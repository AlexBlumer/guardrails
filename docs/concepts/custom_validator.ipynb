{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Validator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the implementation of custom validators easier, we have provided [an interface in the OSS](https://github.com/guardrails-ai/guardrails/blob/main/guardrails/validator_base.py).\n",
    "\n",
    "There are a few key steps to get up and running with a custom validator:\n",
    "\n",
    "1. Implementing the validator\n",
    "2. Conforming to the required interface\n",
    "3. Running Locally/Submitting to the Validator Hub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's build out a simple custom validator. This validator will check if all text in the input is lowercase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "import requests\n",
    "from guardrails.validator_base import (\n",
    "    FailResult,\n",
    "    PassResult,\n",
    "    ValidationResult,\n",
    "    Validator,\n",
    "    register_validator,\n",
    "    ErrorSpan,\n",
    ")\n",
    "\n",
    "\n",
    "@register_validator(name=\"guardrails/lower_case\", data_type=\"string\")\n",
    "class LowercaseValidator(Validator):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        self.rail_alias = \"lowercase\"\n",
    "\n",
    "    def _validate(self, value: Any, metadata: Dict[str, Any]) -> ValidationResult:\n",
    "        if not isinstance(value, str):\n",
    "            return FailResult(error_message=\"Input must be a string.\", fix_value=None)\n",
    "\n",
    "        inference_result = self._inference(value)\n",
    "\n",
    "        if inference_result:\n",
    "            return PassResult()\n",
    "        else:\n",
    "            return FailResult(\n",
    "                error_message=\"Input must be lowercase.\", fix_value=value.lower()\n",
    "            )\n",
    "\n",
    "    def _inference_local(self, model_input: str) -> bool:\n",
    "        \"\"\"Implement a function to perform inference on a local machine.\"\"\"\n",
    "        return model_input.islower()\n",
    "\n",
    "    def _inference_remote(self, model_input: str) -> bool:\n",
    "        \"\"\"Implement a function that will build a request and perform inference on a\n",
    "        remote machine. This is not required if you will always use local mode.\n",
    "        \"\"\"\n",
    "        response = requests.post(self.validation_endpoint, json={\"inputs\": model_input})\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(\n",
    "                f\"Remote inference failed with status code {response.status_code}\"\n",
    "            )\n",
    "\n",
    "        return response.json().get(\"is_lowercase\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple usage running locally\n",
    "\n",
    "If this validator was stored locally in your codebase, you would want to import it\n",
    "\n",
    "```bash\n",
    "from lowercase_validator import LowercaseValidator\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LowercaseValidator.__init__() got an unexpected keyword argument 'use_local'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Usage example:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m lowercase_validator_local \u001b[38;5;241m=\u001b[39m \u001b[43mLowercaseValidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m lowercase_validator_remote \u001b[38;5;241m=\u001b[39m LowercaseValidator(\n\u001b[1;32m      4\u001b[0m     use_local\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, validation_endpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://example.com/validate\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Test cases for local validator\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: LowercaseValidator.__init__() got an unexpected keyword argument 'use_local'"
     ]
    }
   ],
   "source": [
    "# Usage example:\n",
    "lowercase_validator_local = LowercaseValidator(use_local=True)\n",
    "lowercase_validator_remote = LowercaseValidator(\n",
    "    use_local=False, validation_endpoint=\"http://example.com/validate\"\n",
    ")\n",
    "\n",
    "# Test cases for local validator\n",
    "print(lowercase_validator_local(\"hello world\"))  # PassResult\n",
    "print(lowercase_validator_local(\"Hello World\"))  # FailResult\n",
    "print(lowercase_validator_local(\"123\"))  # PassResult (numbers are considered lowercase)\n",
    "print(lowercase_validator_local(123))  # FailResult (not a string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best practice would be to use the validator in a Guardrails.Guard()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some imports\n",
    "from rich import print\n",
    "import guardrails as gd\n",
    "import litellm\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Tell me about the company Apple. Make sure the output is all in lowercase. Don't use any capital letters.\"\n",
    "\n",
    "guard = gd.Guard().use(LowercaseValidator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a guard object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = fragment_generator = guard(\n",
    "    litellm.completion,\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me about LLM streaming APIs.\"},\n",
    "    ],\n",
    "    max_tokens=1024,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like an improved implementation, you can implement the new ErrorSpan feature. This class provides a way to define the span of the error in the input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_validator(name=\"guardrails/lower_case\", data_type=\"string\")\n",
    "class LowercaseValidator(Validator):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        self.rail_alias = \"lowercase\"\n",
    "\n",
    "    def _validate(self, value: Any, metadata: Dict[str, Any]) -> ValidationResult:\n",
    "        if not isinstance(value, str):\n",
    "            return FailResult(error_message=\"Input must be a string.\", fix_value=None)\n",
    "\n",
    "        inference_result = self._inference(value)\n",
    "\n",
    "        if inference_result:\n",
    "            return PassResult()\n",
    "        else:\n",
    "            return FailResult(\n",
    "                error_message=\"Input must be lowercase.\", fix_value=value.lower()\n",
    "            )\n",
    "\n",
    "    def _inference_local(self, model_input: str) -> bool:\n",
    "        \"\"\"Implement a function to perform inference on a local machine.\"\"\"\n",
    "        error_spans = []\n",
    "        start = None\n",
    "\n",
    "        for i, char in enumerate(model_input):\n",
    "            if char.isupper():\n",
    "                if start is None:\n",
    "                    start = i\n",
    "            elif start is not None:\n",
    "                error_spans.append(ErrorSpan(start, i - 1))\n",
    "                start = None\n",
    "\n",
    "        if start is not None:\n",
    "            error_spans.append(ErrorSpan(start, len(model_input) - 1))\n",
    "\n",
    "        return error_spans\n",
    "\n",
    "    def _inference_remote(self, model_input: str) -> bool:\n",
    "        \"\"\"Implement a function that will build a request and perform inference on a\n",
    "        remote machine. This is not required if you will always use local mode.\n",
    "        \"\"\"\n",
    "        response = requests.post(self.validation_endpoint, json={\"inputs\": model_input})\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(\n",
    "                f\"Remote inference failed with status code {response.status_code}\"\n",
    "            )\n",
    "\n",
    "        return response.json().get(\"is_lowercase\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = fragment_generator = guard(\n",
    "    litellm.completion,\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me about LLM streaming APIs.\"},\n",
    "    ],\n",
    "    max_tokens=1024,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
